{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogLeNet_chest_X_ray_image_binary_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6Q6dGD8zvXt/0/cFvF79h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyesukim1/chest_X_ray_images_binary_classification/blob/main/GoogLeNet_chest_X_ray_image_binary_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle API로 연결하여 데이터 로드\n"
      ],
      "metadata": {
        "id": "puLQWAzJlFUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWTESRSCk1XV"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "metadata": {
        "id": "npG138wllaj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "5R6jEk2wlpF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/chest-xray-pneumonia.zip\""
      ],
      "metadata": {
        "id": "RybT-WpUl6Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WvhjvdWPmIn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/chest_xray/'\n",
        "\n",
        "train_path = data_path + 'train'\n",
        "valid_path = data_path + 'val'\n",
        "test_path = data_path + 'test'"
      ],
      "metadata": {
        "id": "Cb1qWyRGmJLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "print(f'number of train data: {len(glob(train_path + \"/*/*\"))}')\n",
        "print(f'number of validation data: {len(glob(valid_path + \"/*/*\"))}')\n",
        "print(f'number of test data: {len(glob(test_path + \"/*/*\"))}')"
      ],
      "metadata": {
        "id": "hqAuepanyMYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '73'\n",
        "\n",
        "seed = 73\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "img_map = []\n",
        "\n",
        "def prepareData(Dir, start):\n",
        "  category = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "  for category in category:\n",
        "    path = os.path.join(Dir, category)\n",
        "    class_num = category.index(category)\n",
        "\n",
        "    for img in tqdm(os.listdir(path)):\n",
        "      img_path = os.path.join(path, img)\n",
        "      img_map.append({'path':img_path, 'label':category})\n",
        "\n",
        "prepareData(train_path, 'train')\n",
        "prepareData(valid_path, 'val')\n",
        "prepareData(test_path, 'test')\n",
        "\n",
        "img_map = pd.DataFrame(img_map).sample(frac=1, random_state=seed)"
      ],
      "metadata": {
        "id": "EuwSgqtNyjmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_map.shape"
      ],
      "metadata": {
        "id": "KjpfrvdVDsya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "features = img_map['path'].to_numpy()\n",
        "labels = img_map['label'].to_numpy()\n",
        "\n",
        "stratified_sample = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=73)\n"
      ],
      "metadata": {
        "id": "Lt79Jot33lzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_index, test_index in stratified_sample.split(features, labels):\n",
        "  X_train, test_X = features[train_index], features[test_index]\n",
        "  y_train, test_y = labels[train_index], labels[test_index]\n",
        "\n",
        "half_size = np.int(len(test_X)/2)\n",
        "X_test, y_test = test_X[0:half_size], test_y[0:half_size]\n",
        "X_val, y_val = test_X[half_size:], test_y[half_size:]"
      ],
      "metadata": {
        "id": "9OUiDtn4EZ_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_map = pd.DataFrame()\n",
        "train_map['path'], train_map['label'] = X_train, y_train\n",
        "\n",
        "test_map = pd.DataFrame()\n",
        "test_map['path'], test_map['label'] = X_test, y_test\n",
        "\n",
        "val_map = pd.DataFrame()\n",
        "val_map['path'], val_map['label'] = X_val, y_val"
      ],
      "metadata": {
        "id": "ishctiiwGfif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data summary\n",
        "print('> {} train size'.format(X_train.shape[0]))\n",
        "print('> {} test size'.format(X_test.shape[0]))\n",
        "print('> {} val size'.format(X_val.shape[0]))"
      ],
      "metadata": {
        "id": "-nkMk8WVGndV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import imageio\n",
        "\n",
        "ColorCh = 3\n",
        "IMG_SIZE = 224\n",
        "input_shape=(IMG_SIZE, IMG_SIZE, ColorCh)\n",
        "\n",
        "classes = (\"NORMAL\", \"PNEMONIA\")\n",
        "CATEGORIES = sorted(classes)\n",
        "\n",
        "print('classes:', CATEGORIES)"
      ],
      "metadata": {
        "id": "g-FftpsYGtOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                             horizontal_flip=True,\n",
        "                             brightness_range=[1.0, 1.3],\n",
        "                             rotation_range=15\n",
        "                             )"
      ],
      "metadata": {
        "id": "P7BakqA7HjeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "def get_generator(frame_):\n",
        "  generator = datagen.flow_from_dataframe(\n",
        "      dataframe=frame_,\n",
        "      x_col = 'path',\n",
        "      y_col = 'label',\n",
        "      batch_size=batch_size,\n",
        "      seed=seed,\n",
        "      shuffle = False,\n",
        "      class_mode='sparse',\n",
        "      color_mode='rgb',\n",
        "      save_format='jpeg',\n",
        "      target_size=(IMG_SIZE, IMG_SIZE)\n",
        "  )\n",
        "  return generator"
      ],
      "metadata": {
        "id": "bPtruKamKwAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLabelCount(frame):\n",
        "    label_count = pd.Series(frame['label'].values.ravel()).value_counts()\n",
        "    n_classes = (label_count)\n",
        "    return label_count"
      ],
      "metadata": {
        "id": "0ZyLMzRUMK_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_map.sample(frac=1, random_state=seed)\n",
        "train_generator = get_generator(train_df)\n",
        "\n",
        "print('훈련 셋의 라벨 갯수')\n",
        "getLabelCount(train_df)"
      ],
      "metadata": {
        "id": "Ryynehp0LbM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = val_map.sample(frac=1, random_state=seed)\n",
        "test_generator = get_generator(val_df)\n",
        "\n",
        "print('검증 셋의 라벨 갯수')\n",
        "getLabelCount(val_df)"
      ],
      "metadata": {
        "id": "IShaJXULMs5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_map.sample(frac=1, random_state=seed)\n",
        "test_generator = get_generator(test_df)\n",
        "\n",
        "print('테스트 셋의 라벨 갯수')\n",
        "getLabelCount(test_df)"
      ],
      "metadata": {
        "id": "0LOiWURmL-5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "g4H7AIxzM4r8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Models"
      ],
      "metadata": {
        "id": "YgWmKpIXM6Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import separable_conv2d\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add, add\n",
        "from tensorflow.keras.layers import InputLayer, Input, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import Activation, MaxPool2D, ZeroPadding2D, SeparableConv2D\n",
        "from keras.layers.normalization import batch_normalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "\n",
        "kernel_regularizer = regularizers.l2(0.0001)\n",
        "\n",
        "final_activation = 'softmax'\n",
        "entropy = 'sparse_categorical_crossentropy'\n",
        "n_classes = len(CATEGORIES)\n",
        "print(n_classes)"
      ],
      "metadata": {
        "id": "ST_m5__iM2rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FCLayers(baseModel):\n",
        "  baseModel.trainable = True\n",
        "  headModel = baseModel.output\n",
        "  headModel = Dropout(0.5, seed=73)(headModel)\n",
        "  headModel = Dense(n_classes, activtion=final_activation)(headModel)\n",
        "  model = Model(inputs = baseModel.input, outputs = headModel)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "038TQz5WOXAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GoogLenet 모델"
      ],
      "metadata": {
        "id": "OsM0eSPKPxYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception Block 만들기\n",
        "\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "def Inception_block(input_layer, f1, f2, f3, f4):    \n",
        "    \n",
        "    path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
        "    \n",
        "    path2 = Conv2D(filters = f2[0], kernel_size = (1,1), \n",
        "                   padding = 'same', activation = 'relu')(input_layer)\n",
        "    \n",
        "    path2 = Conv2D(filters = f2[1], kernel_size = (3,3), \n",
        "                   padding = 'same', activation = 'relu')(path2)\n",
        "\n",
        "    path3 = Conv2D(filters = f3[0], kernel_size = (1,1), \n",
        "                   padding = 'same', activation = 'relu')(input_layer)\n",
        "    \n",
        "    path3 = Conv2D(filters = f3[1], kernel_size = (5,5), \n",
        "                   padding = 'same', activation = 'relu')(path3)\n",
        "\n",
        "    path4 = MaxPooling2D((3,3), strides= (1,1), \n",
        "                         padding = 'same')(input_layer)\n",
        "    \n",
        "    path4 = Conv2D(filters = f4, kernel_size = (1,1), \n",
        "                   padding = 'same', activation = 'relu')(path4)\n",
        "    \n",
        "    output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
        "\n",
        "    return output_layer"
      ],
      "metadata": {
        "id": "7tEhyzXVPw-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WClEGaNiPvWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}